# Personal Insurance Chatbot â€” Fullstack JS (Vite + Express + MongoDB)

Chatbot Ã  dÃ©ployer en local pour poser des questions sur ses contrats d'assurance sans envoyer ses infos persos Ã  OpenAI.

## But du projet

DÃ©velopper une application capable d'assister un utilisateur dans la comprÃ©hension de ses contrats d'assurance, Ã  l'aide d'un chatbot intelligent.

## Etat actuel (Livrables semaine 11 projet fil rouge)

SÃ©curisation de l'app :

- âœ… Pages d'authentification Firebase (SignIn/SignUp).
- âœ… Middleware de vÃ©rification du token Firebase sur toutes les routes du backend.
- âœ… ContrÃ´le dâ€™accÃ¨s : le backend vÃ©rifie que lâ€™utilisateur accÃ¨de ou modifie uniquement ses propres donnÃ©es (ex: conversations liÃ©es Ã  son compte).
- âœ…

## Suivis des changements entre les livrables

| Semaine | Tag       | Description                                        | Historique GitHub                                                                     |
| ------- | --------- | -------------------------------------------------- | ------------------------------------------------------------------------------------- |
| 6       | `week-06` | Mise en place de la structure fullstack du chatbot | [Voir commits](https://github.com/J28u/insurance_assistant/compare/204a969...week-06) |
| 7       | `week-07` | IntÃ©gration dâ€™un RAG classique                     | [Voir commits](https://github.com/J28u/insurance_assistant/compare/week-06...week-07) |
| 8       | `week-08` | Finalisation d'un POC prÃ©sentable                  | [Voir commits](https://github.com/J28u/insurance_assistant/compare/week-07...week-08) |
| 11      | `week-11` | SÃ©curisation de l'app                              | [Voir commits](https://github.com/J28u/insurance_assistant/compare/week-08...week-11) |

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ backend/                        # Backend Node.js : API Express + Mongoose (MongoDB)
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ models/                 # SchÃ©mas Mongoose pour les collections MongoDB
â”‚       â”‚   â”œâ”€â”€ Conversation.js
â”‚       â”‚   â”œâ”€â”€ Message.js
â”‚       â”‚   â””â”€â”€ User.js
â”‚       â”œâ”€â”€ routes/                 # Routes Express pour l'API REST
â”‚       â”‚   â”œâ”€â”€ conversations.js    # Routes pour la gestion des conversations
â”‚       â”‚   â”œâ”€â”€ users.js            # Routes pour la gestion des utilisateurs
â”‚       â”‚   â”œâ”€â”€ retriever.js        # Routes pour la rÃ©cupÃ©ration de documents pertinents et du prompt enrichi.
â”‚       â”‚   â””â”€â”€ upload.js           # Routes pour le chargement des documents pdfs
â”‚       â””â”€â”€ index.js                # Point d'entrÃ©e backend : connexion DB et configuration des routes
â”‚
â”œâ”€â”€ frontend/                       # Frontend React (Vite)
â”‚   â”œâ”€â”€ public/                     # Fichiers statiques accessibles par le navigateur
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ assets/                 # Images, polices, etc.
â”‚       â”œâ”€â”€ components/             # Composants React rÃ©utilisables
â”‚       â”‚   â”œâ”€â”€ Chat.jsx
â”‚       â”‚   â”œâ”€â”€ Conversation.jsx
â”‚       â”‚   â”œâ”€â”€ DeepseekInput.jsx
â”‚       â”‚   â”œâ”€â”€ Home.jsx
â”‚       â”‚   â”œâ”€â”€ Library.jsx
â”‚       â”‚   â”œâ”€â”€ SignIn.jsx
â”‚       â”‚   â””â”€â”€ SignUp.jsx
â”‚       â”œâ”€â”€ App.jsx                 # Composant racine de l'application
â”‚       â”œâ”€â”€ index.css               # Styles globaux
â”‚       â”œâ”€â”€ main.jsx                # Point d'entrÃ©e principal React
â”‚       â””â”€â”€ style.css               # Styles spÃ©cifiques (boutons, spinner, etc.)
â”‚
â”œâ”€â”€ kedro_pipelines/                # Pipelines de Machine Learning/Data avec Kedro
â”‚   â”œâ”€â”€ conf/                       # Configuration Kedro (catalogues, paramÃ¨tres, logs, prompts)
â”‚   â”‚   â”œâ”€â”€ base/
â”‚   â”‚   â”‚   â”œâ”€â”€ catalog.yml         # DÃ©finition des datasets (inputs/outputs)
â”‚   â”‚   â”‚   â””â”€â”€ parameters.yml      # ParamÃ¨tres globaux des pipelines
â”‚   â”‚   â”œâ”€â”€ local/
â”‚   â”‚   â”‚   â””â”€â”€ credentials.yml     # Secrets et credentials (non versionnÃ©s)
â”‚   â”‚   â”œâ”€â”€ prompt_template/
â”‚   â”‚   â”‚   â””â”€â”€ prompt_assistant.txt # Template de prompt pour le RAG (contexte + question)
â”‚   â”‚   â”œâ”€â”€ logging.yml             # Configuration des logs Kedro
â”‚   â”‚   â””â”€â”€ README.md               # Documentation des configs (gÃ©nÃ©rÃ©e par Kedro)
â”‚   â”œâ”€â”€ data/                       # DonnÃ©es du pipeline (non versionnÃ©es)
â”‚   â”‚   â”œâ”€â”€ 01_raw/                 # DonnÃ©es brutes
â”‚   â”‚   â”œâ”€â”€ 02_intermediate/        # DonnÃ©es intermÃ©diaires
â”‚   â”‚   â”œâ”€â”€ 03_primary/             # DonnÃ©es primaires
â”‚   â”‚   â”œâ”€â”€ 04_feature/             # Features extraites
â”‚   â”‚   â”œâ”€â”€ 05_model_input/         # DonnÃ©es prÃªtes pour les modÃ¨les
â”‚   â”‚   â”œâ”€â”€ 06_models/              # ModÃ¨les entraÃ®nÃ©s
â”‚   â”‚   â”œâ”€â”€ 07_model_output/        # PrÃ©dictions, rÃ©sultats de modÃ¨les
â”‚   â”‚   â””â”€â”€ 08_reporting/           # Rapports, visualisations
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ rag/                    # Package principal Kedro
â”‚   â”‚       â”œâ”€â”€ datasets/           # Datasets personnalisÃ©s (ex: FAISS)
â”‚   â”‚       â”‚   â””â”€â”€ faiss_vectorstore_dataset.py
â”‚   â”‚       â”œâ”€â”€ pipelines/
â”‚   â”‚       â”‚   â”œâ”€â”€ embedding/      # Pipeline d'embedding (vectorisation des documents)
â”‚   â”‚       â”‚   â”‚   â”œâ”€â”€ nodes.py
â”‚   â”‚       â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚       â”‚   â””â”€â”€ rag_classic/    # Pipeline RAG classique (retrieval + prompt)
â”‚   â”‚       â”‚       â”œâ”€â”€ nodes.py
â”‚   â”‚       â”‚       â””â”€â”€ pipeline.py
â”‚   â”‚       â”œâ”€â”€ __main__.py         # EntrÃ©e CLI du package Kedro
â”‚   â”‚       â”œâ”€â”€ pipeline_registry.py# DÃ©claration des pipelines disponibles
â”‚   â”‚       â”œâ”€â”€ run_kedro.py        # Script de lancement d'un pipeline via kedro-boot
â”‚   â”‚       â””â”€â”€ settings.py         # Hooks et configuration avancÃ©e Kedro
â”‚   â””â”€â”€ pyproject.toml              # Packaging, dÃ©pendances et config du sous-projet Kedro
â”‚
â”œâ”€â”€ requirements.txt                # DÃ©pendances Python globales du projet
â”œâ”€â”€ .gitignore                      # Fichiers et dossiers Ã  ignorer par git
â””â”€â”€ README.md                       # Documentation principale du projet
```

## ğŸš€ Installation

### PrÃ©requis

- Node.js (v18+ recommandÃ©)
- MongoDB (local ou en ligne via MongoDB Atlas)

### 1. Cloner le projet

```bash
git clone https://github.com/J28u/insurance_assistant.git
cd insurance_assistant
```

### 2. CrÃ©er une base MongoDB (pour l'historisation des conversations)

- appeler cette base 'chatbotdb'
- crÃ©er une collection users avec un utilisateur dont l'id est 68235ea293d0a7e8eab16d47
- crÃ©er un fichier .env dans /backend/src avec les variables suivantes :

```env
MONGODB_URL = mongodb+srv://<db_username>:<db_password>@cluster0.agni83b.mongodb.net/chatbotdb?retryWrites=true&w=majority&appName=Cluster0
```

### 3. Installer les dÃ©pendances Python (Kedro, LangChain, etc.)

```bash
pip install -r requirements.txt
```

### 4. DÃ©ployer le LLM

- [installer Ollama](https://ollama.com/download)
- tÃ©lÃ©charger le modÃ¨le choisi depuis Huggingface

```
ollama pull hf.co/cognitivecomputations/Dolphin3.0-Llama3.1-8B-GGUF:Q6_K
```

- renseigner le nom du modÃ¨le dans le frontend (DeepseekInput ligne 79)

```
 model: "hf.co/cognitivecomputations/Dolphin3.0-Llama3.1-8B-GGUF:Q6_K"
```

- lancer le serveur en arriÃ¨re plan

```
ollama serve
```

### 5. DÃ©ployer le backend

- installer les dÃ©pendances

```bash
cd backend
npm install
```

- lancer l'api :

```bash
cd src
node index.js
```

### 6. DÃ©ployer le frontend

- installer les dÃ©pendances

```bash
cd frontend
npm install
```

- lancer l'application

```bash
cd src
npm run dev
```

### 7. Utilisation des pipelines Kedro

#### Changer le modÃ¨le d'embedding utilisÃ© par le rag:

- Le chargement d'un pdf, entraine la crÃ©ation d'un vectorstore FAISS, sauvegardÃ© localement dans ['data/04_feature/'](kedro_pipelines/data/04_feature/)
- Aller dans [conf/base/parameters.yml](kedro_pipelines/conf/base/parameters.yml)

```bash
embedding_model_name: "OrdalieTech/Solon-embeddings-large-0.1"
```

Par dÃ©faut, [Solon-embeddings-large-0.1](https://huggingface.co/OrdalieTech/Solon-embeddings-large-0.1) est utilisÃ©.

#### Lancer un pipeline Kedro

- Le dossier [src](kedro_pipelines/src) contient des "packages" Kedro, chaque 'package' contient plusieurs pipelines rÃ©pertoriÃ©s dans un fichier [pipeline_registry](kedro_pipelines/src/rag/pipeline_registry.py).

- Pour choisir quel 'package' faire tourner, il faut modifier le fichier [pyproject.toml](kedro_pipelines/pyproject.toml)

```bash
[tool.kedro]
package_name = "rag"
```

- Pour exÃ©cuter un pipeline du package selectionnÃ© : kedro run --pipeline <nom_du_pipeline>

```bash
kedro run --pipeline embedding
```

Vous trouverez les noms de pipelines Ã  exÃ©cuter dans [pipeline_registry](kedro_pipelines/src/rag/pipeline_registry.py). Par exemple: embedding, classic_rag.

Pour plus d'options, veuillez consulter la documentation [Kedro](https://docs.kedro.org)

#### Bonnes pratiques Kedro

- Ne supprimez aucune ligne du fichier .gitignore fourni.
- Ne versionnez pas de donnÃ©es dans votre dÃ©pÃ´t. Gardez les dans ['data/'](kedro_pipelines/data)
- Ne versionnez pas de mots de passe ou de configuration locale dans votre dÃ©pÃ´t. Gardez toutes vos informations sensibles et configurations locales dans ['conf/local/'](kedro_pipelines/conf/local/).

## ğŸ“¡ API - Endpoint principaux

- POST /api/conversations/ : crÃ©er une nouvelle conversation
- GET /api/conversations/user/:userId : rÃ©cupÃ©rer les conversations dâ€™un utilisateur
- GET /api/conversations/onlyone/:conversationId : rÃ©cupÃ©rer les messages dâ€™une conversation
- POST /api/upload/ : charger des pdfs, les dÃ©couper en chunks et sauvegarder leurs embeddings dans une base vectorielle.
- GET /api/retriever/prompt_with_context/:question : rÃ©cupÃ©rer un prompt enrichi d'un contexte pertinent.

## ğŸ§© Composants React

- DeepseekInput.jsx : champ de message + boutons pour interagir avec le LLM
- Conversation.jsx : affichage de la conversation (titre, messages utilisateur et LLM)
- App.jsx : assemble lâ€™interface

## âœ¨ FonctionnalitÃ©s

- CrÃ©ation d'une conversation
- Envoi de messages Ã  un LLM
- Historisation dans MongoDB
- UI dynamique avec React

## ğŸ“š Sources

- Tutoriel Clone de DeepSeek : [Youtube](https://www.youtube.com/watch?v=y3K4hji9W8g)
